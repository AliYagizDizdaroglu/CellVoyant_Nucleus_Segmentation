{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8525124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "import cv2\n",
    "\n",
    "main_path = r\"C:\\Users\\firat\\Desktop\\Yagiz\"\n",
    "\n",
    "os.chdir(main_path)\n",
    "\n",
    "# Images to Numpy\n",
    "\n",
    "path = r\"C:\\Users\\firat\\Desktop\\Yagiz\\TrainVal\"\n",
    "os.chdir(path)\n",
    "dosya = os.listdir(path)\n",
    "\n",
    "size_ori = 1228\n",
    "size_new = 768\n",
    "\n",
    "sayi = len(dosya)\n",
    "\n",
    "images = np.zeros((sayi*4,size_new,size_new,1),dtype=np.float16)\n",
    "i = 0\n",
    "for data in dosya:\n",
    "    i = i + 1\n",
    "    im = io.imread(data)\n",
    "    im2 = resize(im, (size_ori, size_ori)) # Normalization\n",
    "    \n",
    "    new_img = np.zeros([size_new*2,size_new*2,1])\n",
    "    new_img[0:size_ori,0:size_ori,0] = im2\n",
    "    \n",
    "    im_1 = new_img[0:768,0:768,:]\n",
    "    im_2 = new_img[0:768,768:1536,:]\n",
    "    im_3 = new_img[768:1540,0:768,:]\n",
    "    im_4 = new_img[768:1536,768:1536,:]\n",
    "    \n",
    "    images[4*i-4,:,:,0] = im_1[:,:,0]\n",
    "    images[4*i-3,:,:,0] = im_2[:,:,0]\n",
    "    images[4*i-2,:,:,0] = im_3[:,:,0]\n",
    "    images[4*i-1,:,:,0] = im_4[:,:,0]\n",
    "\n",
    "os.chdir(main_path)\n",
    "\n",
    "np.save('train_x', images)\n",
    "\n",
    "# Labels to Numpy\n",
    "\n",
    "path = r\"C:\\Users\\firat\\Desktop\\Yagiz\\TrainVal_Masks\"\n",
    "os.chdir(path)\n",
    "dosya_2 = os.listdir(path)\n",
    "\n",
    "size_ori = 1228\n",
    "size_new = 768\n",
    "\n",
    "sayi = len(dosya_2)\n",
    "\n",
    "labels = np.zeros((sayi*4,size_new,size_new,2),dtype=np.uint8)\n",
    "\n",
    "i = 0\n",
    "for data in dosya_2:\n",
    "    i = i + 1\n",
    "    im = io.imread(data)  \n",
    "    \n",
    "    new_label = np.zeros([size_new*2,size_new*2])\n",
    "    new_label[0:size_ori,0:size_ori] = im\n",
    "    \n",
    "    new_label = new_label > 0.5\n",
    "    T = new_label == 1\n",
    "    F = new_label == 0\n",
    "    \n",
    "    label_1 = new_label[0:768,0:768]\n",
    "    label_2 = new_label[0:768,768:1536]\n",
    "    label_3 = new_label[768:1540,0:768]\n",
    "    label_4 = new_label[768:1536,768:1536]\n",
    "    \n",
    "    labels[4*i-4,:,:,0] = label_1 == 1\n",
    "    labels[4*i-4,:,:,1] = label_1 == 0\n",
    "    \n",
    "    labels[4*i-3,:,:,0] = label_2 == 1\n",
    "    labels[4*i-3,:,:,1] = label_2 == 0\n",
    "    \n",
    "    labels[4*i-2,:,:,0] = label_3 == 1\n",
    "    labels[4*i-2,:,:,1] = label_3 == 0\n",
    "    \n",
    "    labels[4*i-1,:,:,0] = label_4 == 1\n",
    "    labels[4*i-1,:,:,1] = label_4 == 0\n",
    "  \n",
    "os.chdir(main_path)\n",
    "\n",
    "np.save('train_y',labels)\n",
    "\n",
    "#%% Go to main directory\n",
    "\n",
    "os.chdir(main_path)\n",
    "\n",
    "#%% Numpy Load\n",
    "\n",
    "train_x= np.load('train_x.npy')\n",
    "train_y= np.load('train_y.npy')\n",
    "\n",
    "# Model Creation\n",
    "\n",
    "import os\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.convolutional import MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D\n",
    "\n",
    "model = 'standart_unet'\n",
    "\n",
    "shape = (768, 768, 1)\n",
    "class_number = 2\n",
    "\n",
    "def model_create(input_shape=shape,\n",
    "                 num_classes=class_number):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a = Conv2D(64, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(128, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0 = Conv2D(128, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(256, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(256, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(512, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(512, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down2_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down2, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down1, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down0, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down0a, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    # 128\n",
    "\n",
    "    # classify\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model\n",
    "\n",
    "network = model_create(input_shape=shape, num_classes=class_number)\n",
    "network.summary()\n",
    "\n",
    "# Model Save\n",
    "\n",
    "model_file = model + '.json'\n",
    "\n",
    "model_json = network.to_json()\n",
    "with open(model_file, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "#% Model Load\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model = 'standart_unet'\n",
    "\n",
    "path = model + '.json'\n",
    "\n",
    "json_file = open(path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "network = model_from_json(loaded_model_json)\n",
    "\n",
    "# Training\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyper-parameters\n",
    "opt = Adam(lr=0.001, beta_1=0.5)\n",
    "loss_func = \"binary_crossentropy\"\n",
    "network.compile(loss=loss_func, optimizer=opt, metrics=[\"accuracy\"])\n",
    "nb_epoch = 50\n",
    "batch_size = 1\n",
    "\n",
    "# Chechpoint\n",
    "filepath=model + 'weights--{epoch:02d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Training\n",
    "history = network.fit(train_x, train_y, \n",
    "                 batch_size=batch_size, \n",
    "                 callbacks=callbacks_list,\n",
    "                 epochs=nb_epoch, verbose=1,\n",
    "                 validation_split = 0.2\n",
    "                 )\n",
    "\n",
    "# Save Results (Images)\n",
    "\n",
    "from skimage.morphology import dilation\n",
    "from skimage.morphology import disk\n",
    "\n",
    "network.load_weights('standart_unetweights--27.hdf5')\n",
    "\n",
    "path = r\"C:\\Users\\firat\\Desktop\\Yagiz\\Test\"\n",
    "os.chdir(path)\n",
    "test_list = os.listdir(path)\n",
    "\n",
    "size_ori = 1228\n",
    "size_new = 768    \n",
    "    \n",
    "for name in test_list:\n",
    "    \n",
    "    im = io.imread(name)\n",
    "    im = resize(im, (size_ori, size_ori)) # Normalization\n",
    "    \n",
    "    new_img = np.zeros([size_new*2,size_new*2,1])\n",
    "    new_img[0:size_ori,0:size_ori,0] = im\n",
    "    \n",
    "    im_1 = new_img[0:768,0:768,:]\n",
    "    im_2 = new_img[0:768,768:1536,:]\n",
    "    im_3 = new_img[768:1540,0:768,:]\n",
    "    im_4 = new_img[768:1536,768:1536,:]\n",
    "    \n",
    "    A = np.zeros((1,768,768,1))\n",
    "    A[0,:,:,:] = im_1\n",
    "    B = network.predict(A)\n",
    "    C = B[:,:,:,0]\n",
    "    D = C>0.5\n",
    "    D_1 = D[0,:,:]\n",
    "    \n",
    "    A = np.zeros((1,768,768,1))\n",
    "    A[0,:,:,:] = im_2\n",
    "    B = network.predict(A)\n",
    "    C = B[:,:,:,0]\n",
    "    D = C>0.5\n",
    "    D_2 = D[0,:,:]\n",
    "    \n",
    "    A = np.zeros((1,768,768,1))\n",
    "    A[0,:,:,:] = im_3\n",
    "    B = network.predict(A)\n",
    "    C = B[:,:,:,0]\n",
    "    D = C>0.5\n",
    "    D_3 = D[0,:,:]\n",
    "    \n",
    "    A = np.zeros((1,768,768,1))\n",
    "    A[0,:,:,:] = im_4\n",
    "    B = network.predict(A)\n",
    "    C = B[:,:,:,0]\n",
    "    D = C>0.5\n",
    "    D_4 = D[0,:,:]\n",
    "    \n",
    "    result = np.zeros([size_new*2,size_new*2])\n",
    "    \n",
    "    result[0:768,0:768] = D_1\n",
    "    result[0:768,768:1536] = D_2\n",
    "    result[768:1536,0:768] = D_3\n",
    "    result[768:1536,768:1536] = D_4\n",
    "    \n",
    "    sonuc = sonuc[0:size_ori,0:size_ori]\n",
    "    \n",
    "    x = 1\n",
    "    ex = disk(x)\n",
    "    result = dilation(sonuc, ex)\n",
    "    \n",
    "    name_img = 'Result_' + 'U-Net' + '_' + name + '.jpg'\n",
    "    cv2.imwrite(isim, 255*sonuc)\n",
    "\n",
    "# Statistics\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
